{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c1a119b",
   "metadata": {},
   "source": [
    "# Explaining Distribution Shifts in Time using Lime and Some Standard Classifiers\n",
    "\n",
    "In this notebook, we will utilise MNIST to create our own simple dataset with images of geometric shapes that includes a distribution shift in time. We will then use standard classifiers to classify whether the image was present before or after the shift and explain those classifications using Lime.\n",
    "\n",
    "__THE LIME PACKAGE NEEDS TO BE INSTALLED TO RUN THIS EXAMPLE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a901eff5-4f5b-4455-8f75-d3e59a7a7f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import gray2rgb, rgb2gray, label2rgb # since the code wants color images\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bee15b",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "You can either cache the dataset (size ~ 900MB) or load it anew each time you start the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322eb85-566c-4153-acd8-997a02fa3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapt image format for lime_image\n",
    "X_vec = np.array(mnist.data).reshape((-1, 28, 28))\n",
    "y_vec = np.array(mnist.target).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae24dff",
   "metadata": {},
   "source": [
    "## Creating our Artificial Dataset\n",
    "\n",
    "For this notebook, we derive images from MNIST that show vertical lines (normal ones), horizontal lines (rotated ones) and plus signs (a combination of the two). That way, we design three classes with very simple geometric features. This is ideal to test how well a model can explain detected drift if we construct our data so that one class is only present before, one only after the drift and the third class remains consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ee9f5-4156-4e72-998f-a86a66ce26cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec_1 = X_vec[y_vec == 1]\n",
    "\n",
    "X_vec_1_turned = np.swapaxes(X_vec_1, 1,2)[np.random.permutation(X_vec_1.shape[0])] # horizontal line\n",
    "X_vec_1 = X_vec_1[np.random.permutation(X_vec_1.shape[0])] # vertical line\n",
    "\n",
    "#we combine the two lines to get a \"+\"\n",
    "X_vec_plus = np.concatenate( (X_vec_1[np.random.permutation(X_vec_1.shape[0])][:,:,:,None],X_vec_1_turned[np.random.permutation(X_vec_1_turned.shape[0])][:,:,:,None]), axis=3).max(axis=3)\n",
    "\n",
    "y = np.array(X_vec_1.shape[0]*[0]+X_vec_1_turned.shape[0]*[1]+X_vec_plus.shape[0]*[2])\n",
    "X = np.vstack( (X_vec_1, X_vec_1_turned, X_vec_plus) )\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.imshow(X_vec_1.mean(axis=0), interpolation = 'none')\n",
    "ax1.set_title(\"Average of digit 1 - A vertical line\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.imshow(X_vec_1_turned.mean(axis=0), interpolation = 'none')\n",
    "ax1.set_title(\"Average of digit 1 rotated - A horizontal line\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.imshow(X_vec_plus.mean(axis=0), interpolation = 'none')\n",
    "ax1.set_title(\"Both averages combined - a plus sign\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa4bf9",
   "metadata": {},
   "source": [
    "## Training with the Classifier\n",
    "\n",
    "Before we start looking at the quality of our explanations, it is useful to briefly test whether the classifier performs well on our data at all. (As it is a simple dataset with clear features, good performance can be expected but we want to make sure.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d601b96-30f5-4d68-9631-da14f153e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.reshape(-1,28*28), y, test_size=0.50)\n",
    "\n",
    "print(ExtraTreesClassifier(max_depth=3).fit(X_train,y_train).score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddb8f8",
   "metadata": {},
   "source": [
    "Now that we know that our classifier works, we create a stream from our data on which we can actually perform drift detection. The change that occurs with time is simple - during the first n timesteps, we will see only vertical \"lines\" (or ones), while after the shift we will see only horizontal lines (or rotated ones). The \"plus sign\" we created through overlap will be part of the data from before and after the shift. Notice that it has vertical and horizontal lines and thus carries characteristics from both time-points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c3143-acdb-4d15-b74b-4cb2e1896509",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Streams\n",
    "\n",
    "n = 2500\n",
    "sel = np.hstack((np.random.choice(np.where(y!=1)[0], n),np.random.choice(np.where(y!=0)[0], n)))\n",
    "stream_X = X[sel]\n",
    "stream_y = np.array( n*[0]+n*[1] ) #our stream_y now contains info on whether the image is from before or after\n",
    "stream_c = y[sel] #stream_c contains information about the original classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380e79c",
   "metadata": {},
   "source": [
    "With our datastream constructed, we can now define a pipeline to preprocess the data and to apply the classifier to the stream. We then fit this model to out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b68d0f8-8062-44ed-a52c-2693263bc472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Example using the ExtraTreesClassifier on the dataset\n",
    "\n",
    "#making sure our streams have the right types\n",
    "stream_X = np.stack([gray2rgb(iimg) for iimg in stream_X],0).astype(np.uint8)\n",
    "stream_y = stream_y.astype(np.uint8)\n",
    "\n",
    "#helper functions for preprocessing\n",
    "class step_wrap(object):\n",
    "    def __init__(self, step_func):\n",
    "        self._step_func=step_func\n",
    "    def fit(self,*args):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return self._step_func(X)\n",
    "\n",
    "\n",
    "def flatten_step_(images):\n",
    "    flats = []\n",
    "    for img in images:\n",
    "        flats.append(img.ravel())\n",
    "    return flats\n",
    "\n",
    "def makegray_step_(images):\n",
    "    grays = []\n",
    "    for img in images:\n",
    "        grays.append(rgb2gray(img))\n",
    "        \n",
    "    return grays\n",
    "\n",
    "#wrapping up the preprocessing functions\n",
    "\n",
    "makegray_step = step_wrap(makegray_step_)\n",
    "flatten_step = step_wrap(flatten_step_)\n",
    "\n",
    "#defining our pipeline\n",
    "simple_rf_pipeline = Pipeline([\n",
    "   ('Make Gray', makegray_step),\n",
    "    ('Flatten Image', flatten_step),\n",
    "    #('Normalize', Normalizer()),\n",
    "    #('PCA', PCA(5)),\n",
    "    #('RF', RandomForestClassifier())\n",
    "    ('ET',ExtraTreesClassifier(max_depth=8))\n",
    "    #('DT',DecisionTreeClassifier(max_depth=8))\n",
    "    #(\"MLP\",MLPClassifier(max_iter=500))\n",
    "                              ])\n",
    "\n",
    "\n",
    "#fitting the pipeline to our data\n",
    "simple_rf_pipeline.fit(stream_X, stream_y)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9891b2",
   "metadata": {},
   "source": [
    "## Explaining the Results\n",
    "\n",
    "To explain the drift, we use the LimeImageExplainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56230cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer(verbose = False)\n",
    "segmenter = SegmentationAlgorithm('slic', kernel_size=1, max_dist=200, ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f77f72",
   "metadata": {},
   "source": [
    "We apply the explanation algorithm only to a few random example images from MNIST in this notebook. This nicely illustrates which reasons weigh positively and which weigh negatively when it comes to classifying whether a specific image belongs to the period before or after the shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c5330-e9b0-4992-a70e-9cbfa764e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating over all three types of images\n",
    "found = 0\n",
    "for s in [0, 1, 2]:\n",
    "    \n",
    "    legend_s = {0 : \"vertical line\", 1 : \"horizontal line\", 2 : \"combination/plus sign\"}\n",
    "\n",
    "    example = np.random.permutation(np.where(stream_c == s)[0])[0]\n",
    "    print(\"Example number \", example)\n",
    "\n",
    "    #This is where we derive the explanation for the specific example image\n",
    "    explanation = explainer.explain_instance(stream_X[example], \n",
    "                                             classifier_fn = simple_rf_pipeline.predict_proba, \n",
    "                                             top_labels=10, hide_color=0, num_samples=10000, segmentation_fn=segmenter)\n",
    "\n",
    "\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize = (8, 4))\n",
    "    fig.suptitle('Positive/Negative Regions for {} before and after the shift'.format(legend_s[s]))\n",
    "\n",
    "    #Image \"explanation\" before the drift\n",
    "    temp1, mask1 = explanation.get_image_and_mask(0, positive_only=True, num_features=1000, hide_rest=False, min_weight = 0.01)\n",
    "    ax1.imshow(label2rgb(3-mask1,temp1, bg_label = 0), interpolation = 'nearest')\n",
    "    #Image \"explanation\" after the drift\n",
    "    temp2, mask2 = explanation.get_image_and_mask(1, positive_only=True, num_features=1000, hide_rest=False, min_weight = 0.01)\n",
    "    ax2.imshow(label2rgb(3-mask2,temp2, bg_label = 0), interpolation = 'nearest')\n",
    "\n",
    "    if mask1.sum() > 0 and mask2.sum() > 0:      \n",
    "        found += 1\n",
    "\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ba09a",
   "metadata": {},
   "source": [
    "We can see that the lime algorithm shows that the images belonging clearly to either time frame are classified very confidently. The images of the crosses, which were present in equal frequency throughout time, show that the regions that they have in common with either vertical or horizontal lines weigh a little differently when considered for classification before or after the time shift, indicating that the classifier indeed emphasizes the vertical and horizontal line areas especially."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
