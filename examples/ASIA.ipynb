{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "528e9ef9-27dc-4640-9139-ade4398220cd",
   "metadata": {},
   "source": [
    "# Explaining Distribution Shifts in Bayesian Networks using Random Forests and Feature Importance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cb9cc0-4af8-4ad9-b9f9-98f59b059794",
   "metadata": {},
   "source": [
    "Bayes networks play an important role in many areas of science as they allow for an easy-to-read way to convey complex statistical interactions between several variables. Furthermore, they gain relevance from their close connection to computational causality. Here we will analyze data generated by a version of the popular lung cancer (aka Asia) Bayes network.\n",
    "\n",
    "We generated a dataset using the Asia network in which drift is induced by performing an intervention on the ''bronc'' node. The network consists of 8 nodes, each taking on binary values. Before the drift we make use of the standard network, after the drift we increase the chance of ''bronc'' independent of the state of ''smoke'' by 1.5 leading to a chance of ''bronc'' of 0.9 in case ''smoke'' is activated and 0.45 otherwise. This corresponds to a seasonal increase in cases of bronchitis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3194ea-1acd-4089-a30c-84cabd4f201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48534de4-afeb-42ce-855a-ed936ae659ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"asia\",\"tub\",\"smoke\",\"lung\",\"bronc\",\"either\",\"xray\",\"dysp\"]\n",
    "def sample(n = 25000, T=0):\n",
    "    asia   = (np.random.random(size=n) < 0.01).astype(float)\n",
    "    tub    = (np.random.random(size=n) < (asia*0.05 + (1-asia)*0.01)).astype(float)\n",
    "    smoke  = (np.random.random(size=n) < 0.5).astype(float)\n",
    "    lung   = (np.random.random(size=n) < (smoke*0.1 + (1-smoke)*0.01)).astype(float)\n",
    "    bronc  = (np.random.random(size=n) < (smoke*0.6 + (1-smoke)*0.3)*(T*(1/0.6*0.9)+(1-T)*1)).astype(float)\n",
    "    either = (lung + tub > 0).astype(float)\n",
    "    xray   = (np.random.random(size=n) < (either*0.98 + (1-either)*0.05)).astype(float)\n",
    "    dysp   = (np.random.random(size=n) < (bronc*either*0.9 + (1-bronc)*either*0.7 + bronc*(1-either)*0.8 + (1-bronc)*(1-either)*0.1)).astype(float)\n",
    "    \n",
    "    return np.vstack( (asia,tub,smoke,lung,bronc,either,xray,dysp) ).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e93ca-acd3-40d1-b90b-9e9c84bbc7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated data\n",
    "X1,X2 = sample(T=0), sample(T=1)\n",
    "X,T = np.vstack((X1,X2)),np.array(X1.shape[0]*[0]+X2.shape[0]*[1], dtype=float)\n",
    "\n",
    "# Add shadow features for boruta like baseline/analysis\n",
    "X_shadow = np.hstack( (X,np.vstack( [np.random.permutation(X[:,i]) for i in range(X.shape[1]) for _ in range(5)]).T) )\n",
    "features_shadow = features + [s+\" (shadow)\" for s in features for _ in range(5)]\n",
    "\n",
    "# Add noise force the model to learn ''stable'' ruels\n",
    "X_noise = X_shadow + np.random.normal(size=X_shadow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b2cdd-7c1b-4e90-8594-54f14611f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model in a 10-fold way. This allows us to check computational stability of the analysis\n",
    "\n",
    "T = T.astype(int)\n",
    "results = []\n",
    "for train,test in KFold(n_splits=100,shuffle=True).split(X):\n",
    "    model = RandomForestClassifier().fit(X_shadow[train],T[train])\n",
    "    score = model.score(X_shadow[test],T[test])\n",
    "    print(\"Model score on current fold: \", score)\n",
    "    results.append( dict(list(zip(features_shadow,model.feature_importances_))+[(\"score\",score),(\"type\",\"FI\")]) )\n",
    "    results.append( dict(list(zip(features_shadow,permutation_importance(model,X_shadow[test],T[test]).importances_mean))+[(\"score\",score),(\"type\",\"PFI\")]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ec0d85-dd20-4418-9ebc-73e878dd8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df[\"shadow\"] = df.apply(lambda x: max([v for k,v in x.items() if \"shadow\" in k]), axis=1)\n",
    "\n",
    "df[df[\"type\"] == \"FI\"][features+[\"shadow\",\"type\"]].groupby(\"type\").boxplot()\n",
    "df[df[\"type\"] == \"PFI\"][features+[\"shadow\",\"type\"]].groupby(\"type\").boxplot()\n",
    "    \n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
